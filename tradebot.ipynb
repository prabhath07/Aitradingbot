{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement Learning for Stock Market Trading.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('deeplearning': conda)"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "1910d8dd2ad1b217d4d5d21df35379bbdc1e35539664a4d522caaf8125694c5f"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qALiMginGiMW"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as data_reader\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "from collections import deque"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCggfrCtGyiG"
      },
      "source": [
        "class AI_Trader():\n",
        "  \n",
        "  def __init__(self, state_size, action_space=3, model_name=\"AITrader\"): #Stay, Buy, Sell\n",
        "    \n",
        "    self.state_size = state_size\n",
        "    self.action_space = action_space\n",
        "    self.memory = deque(maxlen=2000)\n",
        "    self.inventory = []\n",
        "    self.model_name = model_name\n",
        "    \n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "    self.epsilon_final = 0.01\n",
        "    self.epsilon_decay = 0.995\n",
        "    \n",
        "    self.model = self.model_builder()\n",
        "    \n",
        "  def model_builder(self):\n",
        "    \n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n",
        "    \n",
        "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  def trade(self, state):\n",
        "    \n",
        "    if random.random() <= self.epsilon:\n",
        "      return random.randrange(self.action_space)\n",
        "    \n",
        "    actions = self.model.predict(state)\n",
        "    return np.argmax(actions[0])\n",
        "  \n",
        "  \n",
        "  def batch_train(self, batch_size):\n",
        "    \n",
        "    batch = []\n",
        "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
        "      batch.append(self.memory[i])\n",
        "      \n",
        "    for state, action, reward, next_state, done in batch:\n",
        "      reward = reward\n",
        "      if not done:\n",
        "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "        \n",
        "      target = self.model.predict(state)\n",
        "      target[0][action] = reward\n",
        "      \n",
        "      self.model.fit(state, target, epochs=1, verbose=0)\n",
        "      \n",
        "    if self.epsilon > self.epsilon_final:\n",
        "      self.epsilon *= self.epsilon_decay"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzXG-49iSZX3"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8vVBL8YTGaE"
      },
      "source": [
        "def stocks_price_format(n):\n",
        "  if n < 0:\n",
        "    return \"- $ {0:2f}\".format(abs(n))\n",
        "  else:\n",
        "    return \"$ {0:2f}\".format(abs(n))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAcu8ZZzTNwm"
      },
      "source": [
        "def dataset_loader(stock_name):\n",
        "  \n",
        "  #Complete the dataset loader function\n",
        "  dataset = data_reader.DataReader(stock_name, data_source=\"yahoo\")\n",
        "  \n",
        "  start_date = str(dataset.index[0]).split()[0]\n",
        "  end_date = str(dataset.index[-1]).split()[0]\n",
        "  \n",
        "  close = dataset['Close']\n",
        "\n",
        "  return close"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwTS0EyZ0O1k"
      },
      "source": [
        "def state_creator(data, timestep, window_size):\n",
        "  \n",
        "  starting_id = timestep - window_size + 1\n",
        "  \n",
        "  if starting_id >= 0:\n",
        "    windowed_data = data[starting_id:timestep+1]\n",
        "  else:\n",
        "    windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n",
        "    \n",
        "  state = []\n",
        "  for i in range(window_size - 1):\n",
        "    state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
        "    \n",
        "  return np.array([state])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acuYlqD83xcX"
      },
      "source": [
        "stock_name = \"MSFT\"\n",
        "data = dataset_loader(stock_name)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKfuoXO84c5X"
      },
      "source": [
        "window_size = 10\n",
        "episodes = 1000\n",
        "\n",
        "batch_size = 32\n",
        "data_samples = len(data) - 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4LmF2V94trY"
      },
      "source": [
        "trader = AI_Trader(window_size)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y66jkzwW4wNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "6eef7a3a-6ec5-406b-fa8a-2e6f534415be"
      },
      "source": [
        "trader.model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 32)                352       \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                2112      \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 387       \n=================================================================\nTotal params: 11,171\nTrainable params: 11,171\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0tytPl-5hdg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5211
        },
        "outputId": "d391ac9c-2a60-443b-cfd7-a0abbb0e1ef5"
      },
      "source": [
        "for episode in range(1, episodes + 1):\n",
        "  \n",
        "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
        "  \n",
        "  state = state_creator(data, 0, window_size + 1)\n",
        "  \n",
        "  total_profit = 0\n",
        "  trader.inventory = []\n",
        "  \n",
        "  for t in tqdm(range(data_samples)):\n",
        "    \n",
        "    action = trader.trade(state)\n",
        "    \n",
        "    next_state = state_creator(data, t+1, window_size + 1)\n",
        "    reward = 0\n",
        "    \n",
        "    if action == 1: #Buying\n",
        "      trader.inventory.append(data[t])\n",
        "      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
        "      \n",
        "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
        "      buy_price = trader.inventory.pop(0)\n",
        "      \n",
        "      reward = max(data[t] - buy_price, 0)\n",
        "      total_profit += data[t] - buy_price\n",
        "      print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price) )\n",
        "      \n",
        "    if t == data_samples - 1:\n",
        "      done = True\n",
        "    else:\n",
        "      done = False\n",
        "      \n",
        "    trader.memory.append((state, action, reward, next_state, done))\n",
        "    \n",
        "    state = next_state\n",
        "    \n",
        "    if done:\n",
        "      print(\"########################\")\n",
        "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
        "      print(\"########################\")\n",
        "    \n",
        "    if len(trader.memory) > batch_size:\n",
        "      trader.batch_train(batch_size)\n",
        "      \n",
        "  if episode % 10 == 0:\n",
        "    trader.model.save(\"ai_trader_{}.h5\".format(episode))\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1257 [00:00<?, ?it/s]Episode: 1/1000\n",
            "AI Trader bought:  $ 23.397499\n",
            "AI Trader sold:  $ 23.600000  Profit: $ 0.202501\n",
            "AI Trader bought:  $ 23.900000\n",
            "AI Trader bought:  $ 23.972500\n",
            "AI Trader sold:  $ 23.747499  Profit: - $ 0.152500\n",
            "AI Trader bought:  $ 23.882500\n",
            "AI Trader bought:  $ 24.217501\n",
            "AI Trader sold:  $ 24.697500  Profit: $ 0.725000\n",
            "AI Trader sold:  $ 24.695000  Profit: $ 0.812500\n",
            "AI Trader bought:  $ 24.967501\n",
            "AI Trader sold:  $ 24.857500  Profit: $ 0.639999\n",
            "AI Trader sold:  $ 24.665001  Profit: - $ 0.302500\n",
            "AI Trader bought:  $ 26.512501\n",
            "AI Trader bought:  $ 26.120001\n",
            "AI Trader bought:  $ 26.870001\n",
            "AI Trader bought:  $ 27.092501\n",
            "AI Trader bought:  $ 27.202499\n",
            "AI Trader bought:  $ 26.982500\n",
            "  3%|▎         | 33/1257 [00:04<03:05,  6.61it/s]AI Trader sold:  $ 27.045000  Profit: $ 0.532499\n",
            "  3%|▎         | 34/1257 [00:09<06:35,  3.09it/s]AI Trader sold:  $ 27.370001  Profit: $ 1.250000\n",
            "  3%|▎         | 35/1257 [00:13<11:09,  1.83it/s]AI Trader sold:  $ 27.344999  Profit: $ 0.474998\n",
            "  3%|▎         | 37/1257 [00:21<22:59,  1.13s/it]AI Trader bought:  $ 27.270000\n",
            "  3%|▎         | 38/1257 [00:26<30:44,  1.51s/it]AI Trader sold:  $ 27.340000  Profit: $ 0.247499\n",
            "  3%|▎         | 41/1257 [00:39<54:51,  2.71s/it]AI Trader sold:  $ 27.007500  Profit: - $ 0.195000\n",
            "  3%|▎         | 42/1257 [00:43<1:02:12,  3.07s/it]AI Trader bought:  $ 26.892500\n",
            "  3%|▎         | 43/1257 [00:47<1:08:12,  3.37s/it]AI Trader sold:  $ 26.735001  Profit: - $ 0.247499\n",
            "  4%|▎         | 44/1257 [00:52<1:13:15,  3.62s/it]AI Trader sold:  $ 26.705000  Profit: - $ 0.565001\n",
            "  4%|▎         | 46/1257 [01:00<1:19:54,  3.96s/it]AI Trader sold:  $ 26.525000  Profit: - $ 0.367500\n",
            "  4%|▍         | 49/1257 [01:13<1:24:35,  4.20s/it]AI Trader bought:  $ 26.924999\n",
            "  4%|▍         | 50/1257 [01:17<1:24:34,  4.20s/it]AI Trader bought:  $ 27.090000\n",
            "  4%|▍         | 51/1257 [01:22<1:24:27,  4.20s/it]AI Trader sold:  $ 26.379999  Profit: - $ 0.545000\n",
            "  4%|▍         | 52/1257 [01:26<1:27:30,  4.36s/it]AI Trader sold:  $ 25.782499  Profit: - $ 1.307501\n",
            "  4%|▍         | 52/1257 [01:30<34:49,  1.73s/it]  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-a1a8760d2784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m       \u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-2-85e45d4e54a2>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m       \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1626\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    680\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 705\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   2969\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 2971\u001b[1;33m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[0;32m   2972\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2973\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqc5EbDe-OWs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}